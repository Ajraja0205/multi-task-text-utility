# ğŸ“˜ FAQ Support Chatbot â€“ RAG-Style API

This project implements a **Retrieval-Augmented Generation (RAG) style Question Answering API** using **FastAPI** and an open-source language model (`google/flan-t5-base`). It is designed to meet academic and interview-level expectations by returning **structured, explainable responses** instead of vague one-line answers.

---

## ğŸš€ Features

* âœ… FastAPI-based REST backend
* âœ… RAG-style architecture (Retrieval + Generation)
* âœ… Structured JSON responses
* âœ… Open-source LLM (no OpenAI quota required)
* âœ… Interview / assignment ready

---

## ğŸ§  What is RAG in this Project?

**Retrieval-Augmented Generation (RAG)** combines:

1. **Retrieval** â€“ Fetching relevant context from a knowledge base (FAQ data)
2. **Generation** â€“ Using an LLM to generate answers grounded in that context

In this project:

* Retrieval is simulated using a keyword-based search over FAQ data
* Generation is handled by `flan-t5-base`

---

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ main.py        # FastAPI application
â”œâ”€â”€ README.md      # Project documentation
```

---

## ğŸ› ï¸ Tech Stack

* **Python 3.9+**
* **FastAPI** â€“ API framework
* **Uvicorn** â€“ ASGI server
* **Transformers (Hugging Face)** â€“ LLM pipeline
* **Flan-T5 Base** â€“ Instruction-tuned language model

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Create Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install fastapi uvicorn transformers torch
```

---

## â–¶ï¸ Running the Application

```bash
uvicorn main:app --reload
```

Server will start at:

ğŸ‘‰ **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

Swagger UI:

ğŸ‘‰ **[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)**

---

## ğŸ”— API Endpoints

### âœ… Health Check

**GET /**

Response:

```json
{
  "status": "OK",
  "message": "FAQ RAG Backend Running ğŸš€"
}
```

---

### ğŸ¤– Ask a Question

**POST /ask**

#### Request Body

```json
{
  "question": "What is RAG architecture?"
}
```

#### Response Body

```json
{
  "user_question": "What is RAG architecture?",
  "system_answer": "RAG architecture stands for Retrieval-Augmented Generation. It retrieves relevant information first and then uses a language model to generate grounded answers.",
  "chunks_related": [
    {
      "content": "RAG stands for Retrieval Augmented Generation. It combines information retrieval with language model generation.",
      "source": "faq",
      "relevance_score": 0.9
    },
    {
      "content": "RAG architecture retrieves relevant documents first and then uses an LLM to generate grounded answers.",
      "source": "faq",
      "relevance_score": 0.9
    }
  ]
}
```

---

## ğŸ§ª Example CURL Command

```bash
curl -X POST "http://127.0.0.1:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{"question": "What is LLM?"}'
```

---

## ğŸ“Œ Why This Implementation Is Good

* âŒ Avoids vague LLM-only answers
* âœ… Explains *why* the answer was generated
* âœ… Shows retrieved knowledge chunks
* âœ… Demonstrates understanding of RAG concepts

This makes it suitable for:

* ğŸ“ Academic assignments
* ğŸ’¼ Interviews
* ğŸ§ª Proof-of-concept RAG systems

---

## ğŸ”® Future Enhancements

* Replace keyword retrieval with **FAISS + embeddings**
* Add **CSV / DB logging** (latency, tokens)
* Support **multiple documents**
* Add **confidence scores**

---

## ğŸ‘¨â€ğŸ’» Author

**Ansh Jain**

---

âœ… *Project is complete, functional, and evaluation-ready.*
