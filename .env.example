# LLM Provider (ollama | openai)
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Request settings
LLM_TIMEOUT=60
